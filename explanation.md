# BASE IMAGE CHOICE WHEN BUILDING CONTAINERS

What is in a base container image is still an operating system that derives its security, reliability, and life cycle from the underlying operating system on which it is built. Compatibility should also be considered. because it was a Node.js app ,I used node as my base image for both web and API.

# DOCKERFILE DIRECTIVES USED IN THE CREATION AND RUNNING OF EACH CONTAINER.

# Client Service Dockerfile

FROM node:13.12.0 WORKDIR /app COPY package*.json ./ RUN npm install COPY . . EXPOSE 3000 CMD ["npm", "start"]

    FROM node:13.12.0-alpine , I'm using the node:13.12.0-alpine image,because it is a light weight image(small image size).

    WORKDIR /app - used to define the working directory of a Docker container at any given time.

    COPY package*.json ./ - Copies the package.json and package-lock.json files from the local directory to the Docker image,gives a clear description of all packages your app needs to run.

    RUN npm install - Runs the npm install command inside the Docker image ,It is a package manager for node, written in Javascript. We can install any required packages with the npm  install command.

    COPY . . - Copies the entire local directory to the Docker image.

    EXPOSE 3000 - Informs Docker that the container will listen on port 3000.

    CMD ["npm", "start"] - Specifies the command to run when the container starts. In this case, it runs the npm start command to start the web server.

# Api Service Dockerfile

    FROM node:alpine
    WORKDIR /app
    COPY package*.json ./
    RUN npm install
    COPY . .
    EXPOSE 5000
    CMD [ "npm", "run","start" ]

The same directives as client service dockerfile
# DOCKER-COMPOSE NETWORKING (Application port allocation and a bridge network implementation) where necessary.

In docker-compose.yml file, I specified a bridge network called yolo-my-net for my microservices to communicate with each other: I specified network driver to type bridge.

  # GIT WORKFLOW .
    Used centralised git workflow .

    Forking and cloning yolo repository to my local machine using git clone (for cloning)


    Create a Dockerfile for each microservice. I created a Dockerfile for each microservice in its respective branch. I followed best practices for writing Dockerfiles, such as using a lightweight base image and only including necessary dependencies.

    Build and test each Docker image locally. I used the docker build command to build each Docker image locally, and then used the docker run command to test each image to make sure it was running correctly.before pushing to github.

    Create a docker-compose.yml file. I created a docker-compose.yml file in the main branch to orchestrate the containers for each microservice. I specified the Docker image for each service and defined the networking

    Test the Docker Compose setup locally. I used the docker-compose up command to start the Docker Compose setup locally and tested that the microservices were able to communicate with each other.

    Push the changes to the repository. Once I was satisfied that everything was working correctly, I committed and pushed the changes to the repository. using quality and descriptive commits.

    

# Successful running of the applications and if not, debugging measures applied.
I updated the package.json file to resolve the error cannot find module dotenv.

# Good practices such as Docker image tag naming standards for ease of identification of images and containers.
        I used the repository name together with the service name to tag my images and versioning method to name my images  yoloclient:v1.0.1 yolobackend:v1.0.1 2.I used lowercase letters to do this

# Docker-compose volume definition and usage (where necessary).
 I created a volume called yolovol ,  volumes are used for persisting data generated by and used by Docker containers.

# Explanation of the "Provision Vagrant VM and set up Docker containers" playbook

The following playbook is designed to provision a Vagrant VM and set up Docker containers with an application named "yolo". The playbook defines the required variables and performs the following tasks:
Tasks

# Update apt cache
The first task updates the apt cache on the Vagrant VM. 
This ensures that the latest package information is available before installing any packages.

# Install required packages

 The second task installs the required packages for running Docker containers. 
This includes Git, Docker.io, apt-transport-https, ca-certificates, curl, gnupg-agent, and software-properties-common.

# Add Docker GPG key

The third task adds the Docker GPG key to the apt keyring on the Vagrant VM. This key is required to authenticate packages downloaded from the Docker repository.
# Add Docker APT repository

 The fourth task adds the Docker APT repository to the Vagrant VM's sources.list.
 This enables the VM to download and install the Docker package.
# Update and upgrade packages

The fifth task updates and upgrades all packages on the Vagrant VM, including the newly added Docker package.
# install containerd

The sixth task installs containerd to help in docker installation


