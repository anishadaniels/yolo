# BASE IMAGE CHOICE WHEN BUILDING CONTAINERS

What is in a base container image is still an operating system that derives its security, reliability, and life cycle from the underlying operating system on which it is built. Compatibility should also be considered. because it was a Node.js app ,I used node as my base image for both web and API.

# DOCKERFILE DIRECTIVES USED IN THE CREATION AND RUNNING OF EACH CONTAINER.

# Client Service Dockerfile

FROM node:13.12.0 WORKDIR /app COPY package*.json ./ RUN npm install COPY . . EXPOSE 3000 CMD ["npm", "start"]

    FROM node:13.12.0-alpine , I'm using the node:13.12.0-alpine image,because it is a light weight image(small image size).

    WORKDIR /app - used to define the working directory of a Docker container at any given time.

    COPY package*.json ./ - Copies the package.json and package-lock.json files from the local directory to the Docker image,gives a clear description of all packages your app needs to run.

    RUN npm install - Runs the npm install command inside the Docker image ,It is a package manager for node, written in Javascript. We can install any required packages with the npm  install command.

    COPY . . - Copies the entire local directory to the Docker image.

    EXPOSE 3000 - Informs Docker that the container will listen on port 3000.

    CMD ["npm", "start"] - Specifies the command to run when the container starts. In this case, it runs the npm start command to start the web server.

# Api Service Dockerfile

    FROM node:alpine
    WORKDIR /app
    COPY package*.json ./
    RUN npm install
    COPY . .
    EXPOSE 5000
    CMD [ "npm", "run","start" ]

The same directives as client service dockerfile
# DOCKER-COMPOSE NETWORKING (Application port allocation and a bridge network implementation) where necessary.

In docker-compose.yml file, I specified a bridge network called yolo-my-net for my microservices to communicate with each other: I specified network driver to type bridge.

  # GIT WORKFLOW .
    Used centralised git workflow .

    Forking and cloning yolo repository to my local machine using git clone (for cloning)


    Create a Dockerfile for each microservice. I created a Dockerfile for each microservice in its respective branch. I followed best practices for writing Dockerfiles, such as using a lightweight base image and only including necessary dependencies.

    Build and test each Docker image locally. I used the docker build command to build each Docker image locally, and then used the docker run command to test each image to make sure it was running correctly.before pushing to github.

    Create a docker-compose.yml file. I created a docker-compose.yml file in the main branch to orchestrate the containers for each microservice. I specified the Docker image for each service and defined the networking

    Test the Docker Compose setup locally. I used the docker-compose up command to start the Docker Compose setup locally and tested that the microservices were able to communicate with each other.

    Push the changes to the repository. Once I was satisfied that everything was working correctly, I committed and pushed the changes to the repository. using quality and descriptive commits.

    

# Successful running of the applications and if not, debugging measures applied.
I updated the package.json file to resolve the error cannot find module dotenv.

# Good practices such as Docker image tag naming standards for ease of identification of images and containers.
        I used the repository name together with the service name to tag my images and versioning method to name my images  yoloclient:v1.0.1 yolobackend:v1.0.1 2.I used lowercase letters to do this

# Docker-compose volume definition and usage (where necessary).
 I created a volume called yolovol ,  volumes are used for persisting data generated by and used by Docker containers.

# Ansible Playbook for Deploying YOLO Application

This is an Ansible playbook for deploying the YOLO application on both the frontend and backend servers. The YOLO application is a web-based chat application that allows users to create chat rooms and chat with each other in real-time.
# Server Setup

The playbook assumes that the servers have already been provisioned and are running Ubuntu. It also assumes that Ansible is installed on the control machine and that SSH access to the servers has been set up.
# Playbook Overview

The playbook consists of two roles: "client side" and "backend app". The "client side" role installs and sets up the frontend server, while the "backend app" role installs and sets up the backend server.
# Client Side Role

The "client side" role consists of the following tasks:

    Install GPG
    Install the GPG key for Node.js LTS
    Install the Node.js LTS repos
    Update apt packages
    Install Node.js
    Clone the YOLO repository
    Install dependencies from lockfile
    Start the YOLO application

The role installs Node.js on the frontend server and clones the YOLO repository from GitHub. It also installs the dependencies required to run the application and starts the application.
# Backend App Role

The "backend app" role consists of the following tasks:

    Install GPG
    Install the GPG key for Node.js LTS
    Install the Node.js LTS repos
    Update apt packages
    Install Node.js
    Clone the YOLO repository
    Install dependencies from lockfile
    Start the YOLO application

The role installs Node.js on the backend server and clones the YOLO repository from GitHub. It also installs the dependencies required to run the application and starts the application.
# Variables

The playbook uses the following variable:

    NODEJS_VERSION: specifies the version of Node.js to install. In this playbook, it is set to "14".

# Tags

Tags are used to group tasks together and allow for selective execution of specific tasks. The playbook uses the following tags:

    nodejs: used for tasks related to installing Node.js.
    install: used for tasks related to installing software packages.
    setup: used for tasks related to setting up the servers.
    app: used for tasks related to installing the YOLO application.
    build: used for tasks related to building the application.
    deploy: used for tasks related to deploying the application.

# Conclusion

This Ansible playbook provides an automated way to deploy the YOLO application on both the frontend and backend servers. By using roles, variables, and tags, the playbook can be easily customized and reused for other applications.
